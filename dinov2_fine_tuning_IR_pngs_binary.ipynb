{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pjc4EC_h7N0u"
      },
      "outputs": [],
      "source": [
        "# from dinov2.models.vision_transformer import vit_large\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torchmetrics\n",
        "import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.file_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Loop over the directory structure\n",
        "        for label, class_name in enumerate(os.listdir(root_dir)):\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            if os.path.isdir(class_dir):\n",
        "                for file_name in os.listdir(class_dir):\n",
        "                    file_path = os.path.join(class_dir, file_name)\n",
        "                    if file_name.endswith(\".png\"):\n",
        "                        self.file_paths.append(file_path)\n",
        "                        self.labels.append(label)\n",
        "\n",
        "        print(f\"Loaded {len(self.file_paths)} images from {root_dir}\")\n",
        "        if len(self.file_paths) == 0:\n",
        "            print(f\"No images found in directory: {root_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.file_paths[idx]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, data_dir, batch_size, transform):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            train_dir = os.path.join(self.data_dir, \"train\")\n",
        "            print(f\"Setting up training dataset from {train_dir}\")\n",
        "            train_dataset = ImageDataset(train_dir, transform=self.transform)\n",
        "            num_train = len(train_dataset)\n",
        "            if num_train == 0:\n",
        "                raise ValueError(f\"No training data found in {train_dir}\")\n",
        "            self.train_dataset, self.val_dataset = random_split(\n",
        "                train_dataset, [num_train - 5, 5]\n",
        "            )\n",
        "\n",
        "        if stage == \"test\" or stage is None:\n",
        "            test_dir = os.path.join(self.data_dir, \"test\")\n",
        "            print(f\"Setting up test dataset from {test_dir}\")\n",
        "            self.test_dataset = ImageDataset(test_dir, transform=self.transform)\n",
        "            num_test = len(self.test_dataset)\n",
        "            if num_test == 0:\n",
        "                raise ValueError(f\"No test data found in {test_dir}\")\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "class LinearClassifierHead(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "        self.head = nn.Linear(embed_dim, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.head(x))\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchmetrics\n",
        "import pytorch_lightning as pl\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Load the DINOv2 model\n",
        "dinov2_vits14 = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vits14\")\n",
        "\n",
        "\n",
        "class CustomModel(pl.LightningModule):\n",
        "    def __init__(self, embed_dim, learning_rate):\n",
        "        super().__init__()\n",
        "        self.dinov2_vits14 = dinov2_vits14\n",
        "        self.linear_classifier_head = LinearClassifierHead(embed_dim)\n",
        "        self.criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
        "        self.learning_rate = learning_rate\n",
        "        self.train_acc = torchmetrics.Accuracy(task=\"binary\")\n",
        "        self.val_acc = torchmetrics.Accuracy(task=\"binary\")\n",
        "        self.test_acc = torchmetrics.Accuracy(task=\"binary\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            features = self.dinov2_vits14(x)\n",
        "        return self.linear_classifier_head(features)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(\n",
        "            self.linear_classifier_head.parameters(), lr=self.learning_rate\n",
        "        )\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        outputs = self(images).squeeze()\n",
        "        loss = self.criterion(outputs, labels.float())\n",
        "        acc = self.train_acc(outputs, labels.int())\n",
        "        self.log(\"train_loss\", loss)\n",
        "        self.log(\"train_acc\", acc)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        outputs = self(images).squeeze()\n",
        "        loss = self.criterion(outputs, labels.float())\n",
        "        acc = self.val_acc(outputs, labels.int())\n",
        "        self.log(\"val_loss\", loss)\n",
        "        self.log(\"val_acc\", acc)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        outputs = self(images).squeeze()\n",
        "        loss = self.criterion(outputs, labels.float())\n",
        "        acc = self.test_acc(outputs, labels.int())\n",
        "        self.log(\"test_loss\", loss)\n",
        "        self.log(\"test_acc\", acc)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of initializing the DataModule and CustomModel for binary classification\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "data_module = DataModule(\n",
        "    data_dir=\"/home/nayoonkim/dino_test/a_notebooks/IR\",\n",
        "    batch_size=8,\n",
        "    transform=transform,\n",
        ")\n",
        "model = CustomModel(embed_dim=dinov2_vits14.embed_dim, learning_rate=1e-3)\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 361,
          "referenced_widgets": [
            "ed3bb7957c7f40aaad803357660f1972",
            "a8fbcdba89764306a6caa93bf9143e5d",
            "721b0963a8f745d293fd2fd47b82eecf",
            "ebefd0d1422445a889d4985618bd482c",
            "599869e2069a4173af3749c581e9e794",
            "b1ab38b03ec8415bab49265b4d8900f6",
            "bd694b7884294caab4287ce57769b0b2",
            "62cd55deffbf4fdcadff85d260d30e91",
            "afd2a3c9b00d45d89271bf02713a9e90",
            "f466bbd60d554f0da33e81982ae73d33",
            "5de3bff41d8547e2a8d67f6b7c8f20ff",
            "9014385c7825447fae61b244edb32f7a"
          ]
        },
        "id": "fXhHFpek7Hta",
        "outputId": "a51f349f-d859-4ea7-dfab-571312bc38e0"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "trainer.fit(model, data_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZJgkV07t7Iot",
        "outputId": "fecab14b-931a-4275-9fcc-b75e43614dab"
      },
      "outputs": [],
      "source": [
        "trainer.test(model, datamodule=data_module)\n",
        "\n",
        "print(\"Training and testing complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Configuration\n",
        "# batch_size = 4\n",
        "# num_epochs = 50\n",
        "# learning_rate = 0.001\n",
        "# transform = transforms.Compose(\n",
        "#     [\n",
        "#         transforms.Resize((224, 224)),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# data_module = DataModule(\n",
        "#     data_dir=\"/home/nayoonkim/dino_test/a_notebooks/IR\", batch_size=batch_size, transform=transform\n",
        "# )\n",
        "# model = CustomModel(embed_dim=dinov2_vits14.embed_dim, num_classes=3, learning_rate=learning_rate)\n",
        "# trainer = pl.Trainer(max_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize the accuracy\n",
        "train_acc = model.train_acc.compute().cpu().numpy()\n",
        "val_acc = model.val_acc.compute().cpu().numpy()\n",
        "test_acc = model.test_acc.compute().cpu().numpy()\n",
        "\n",
        "epochs = range(1, num_epochs + 1)\n",
        "\n",
        "print(train_acc)\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# plt.plot(epochs, train_acc, label='Training Accuracy')\n",
        "# plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.title('Training and Validation Accuracy')\n",
        "# plt.legend()\n",
        "# # plt.show()\n",
        "\n",
        "# # print(\"Training and testing complete.\")\n",
        "\n",
        "# epochs = range(1, num_epochs + 1)\n",
        "\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# plt.plot(epochs, train_acc_history, label='Training Accuracy')\n",
        "# plt.plot(epochs, val_acc_history, label='Validation Accuracy')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.title('Training and Validation Accuracy')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# print(\"Training and testing complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the accuracy\n",
        "train_acc = trainer.callback_metrics[\"train_acc\"].cpu().numpy()\n",
        "val_acc = trainer.callback_metrics[\"val_acc\"].cpu().numpy()\n",
        "test_acc = trainer.callback_metrics[\"test_acc\"].cpu().numpy()\n",
        "\n",
        "epochs = range(1, num_epochs + 1)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, train_acc, label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training and Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Training and testing complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
